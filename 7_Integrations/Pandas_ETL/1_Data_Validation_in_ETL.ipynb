{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 📊 Pandas\\_ETL — Data Validation in ETL\n",
    "\n",
    "### 🎯 Intent\n",
    "\n",
    "Use **Pydantic v2 + Pandas** to validate ETL pipeline data—ensuring rows are clean, typed, and consistent before analytics or storage.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 Core Components\n",
    "\n",
    "1. **🧱 Row Models**\n",
    "\n",
    "   * Define schema with `BaseModel` + field constraints.\n",
    "   * Example fields: `id: int`, `name: str`, `amount: float`.\n",
    "\n",
    "2. **📥 Validate Rows**\n",
    "\n",
    "   * Convert DataFrame rows to dicts.\n",
    "   * Validate with `.model_validate()`.\n",
    "   * Catch `ValidationError` → log/drop.\n",
    "\n",
    "3. **⚡ Batch Validation**\n",
    "\n",
    "   * Use `TypeAdapter(list[Model])` for vectorized checks.\n",
    "   * Much faster for bulk ETL.\n",
    "\n",
    "4. **🛡️ Cleaning**\n",
    "\n",
    "   * Drop invalid rows.\n",
    "   * Fill defaults via field defaults.\n",
    "   * Save errors to logs/quarantine table.\n",
    "\n",
    "5. **📦 Integration**\n",
    "\n",
    "   * Run validation step **before transformations**.\n",
    "   * Build new DataFrame from validated rows.\n",
    "\n",
    "6. **🧪 Common Constraints**\n",
    "\n",
    "   * Ranges (`ge`, `le`), string length, regex patterns.\n",
    "   * Enums (`Literal`, `Enum`).\n",
    "   * Dates (`datetime`, `PastDate`).\n",
    "\n",
    "7. **🔗 Schema Reuse**\n",
    "\n",
    "   * Same Pydantic model can validate both **API inputs** and **ETL rows**.\n",
    "\n",
    "8. **📊 Error Auditing**\n",
    "\n",
    "   * Collect row index + error message.\n",
    "   * Store invalid data separately for review.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
