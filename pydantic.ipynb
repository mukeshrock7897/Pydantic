{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "📘 1. Core Understanding (Essential for LangChain Tools & Agents)\n",
    "│\n",
    "├── What is Pydantic?\n",
    "├── Role in LangChain/LangGraph:\n",
    "│   ├── Tool Input Schema\n",
    "│   ├── Output Parsers\n",
    "│   ├── Agent State validation\n",
    "│   ├── Prompt-to-Tool interaction structure\n",
    "└── Type-safety and validation in chains\n",
    "\n",
    "📦 2. BaseModel (Backbone of LangChain Tool Schemas)\n",
    "│\n",
    "├── Defining Input/Output schemas for:\n",
    "│   ├── @tool decorators\n",
    "│   ├── Runnable interfaces\n",
    "│   ├── LangGraph states and memory\n",
    "├── BaseModel class usage\n",
    "├── model_dump()\n",
    "├── model_validate()\n",
    "├── model_copy()\n",
    "└── model_config (ConfigDict with validation modes)\n",
    "\n",
    "📄 3. Model Fields (Tool Parameters & Agent State)\n",
    "│\n",
    "├── Type-annotated fields (str, int, float, list, etc.)\n",
    "├── Optional/Required fields (Optional[])\n",
    "├── Default values / default_factory\n",
    "├── Field alias (for prompt or tool parameter naming)\n",
    "├── Field metadata:\n",
    "│   ├── description → Used in tool docs/UI\n",
    "│   ├── examples → Used in LangGraph/LLM preview\n",
    "└── Field() for constraints (e.g., min_length, ge)\n",
    "\n",
    "🎯 4. Validation (Ensures tool/agent schema consistency)\n",
    "│\n",
    "├── Validation lifecycle in agent execution\n",
    "├── typing.Annotated for validation hints\n",
    "├── Built-in constraints: ge, le, min_length, etc.\n",
    "├── @field_validator (before/after LLM call)\n",
    "├── @model_validator (cross-field checks)\n",
    "└── Nested model validation (multi-input tools)\n",
    "\n",
    "🧬 5. Model Composition (Multi-step Chains & Memory)\n",
    "│\n",
    "├── Nested models for structured inputs/outputs\n",
    "├── Recursive models for nested tool calls or state trees\n",
    "├── Generic models (not common but usable)\n",
    "└── Inheritance for reusing base schemas (e.g., BaseToolSchema)\n",
    "\n",
    "📤 6. Serialization & Deserialization (Crucial for LangGraph state)\n",
    "│\n",
    "├── model_dump() → serialize state or tool output\n",
    "├── model_dump_json() → serialize for storage\n",
    "├── model_validate() → validate incoming tool inputs\n",
    "├── @field_serializer (for formatting output)\n",
    "└── Serialization aliases (for prompt or UI formatting)\n",
    "\n",
    "🛡️ 7. Strict Mode & Type Safety (Prevents hallucinations or misuse)\n",
    "│\n",
    "├── StrictStr, StrictInt for rigid input parsing\n",
    "├── Prevent coercion from LLM float→str, etc.\n",
    "├── Useful for LangChain+LangGraph guardrails\n",
    "└── pydantic-core: Faster validation for runtime agents\n",
    "\n",
    "🔗 8. Advanced Usage (LangGraph-Specific)\n",
    "│\n",
    "├── Discriminated Unions (agent state switching)\n",
    "│   └── Useful in multi-agent orchestration\n",
    "├── Private attributes (`PrivateAttr`)\n",
    "│   └── Store internal agent metadata (e.g., step count)\n",
    "├── Computed fields (`@computed_field`)\n",
    "│   └── On-the-fly state fields (e.g., elapsed time, token usage)\n",
    "└── __pydantic_fields__ → Introspection during tool chaining\n",
    "\n",
    "📚 9. Error Handling (For Agent Reliability)\n",
    "│\n",
    "├── ValidationError handling in tools and LangGraph\n",
    "├── Custom error messages for LLM feedback\n",
    "└── LangChain tool fallback based on validation failure\n",
    "\n",
    "🔌 10. LangChain & LangGraph Integration Points (Direct Usage)\n",
    "│\n",
    "├── LangChain:\n",
    "│   ├── @tool(..., args_schema=MySchema)\n",
    "│   ├── OutputParser using BaseModel\n",
    "│   └── Prompt Templates with schema injection\n",
    "│\n",
    "├── LangGraph:\n",
    "│   ├── Agent state classes → subclass BaseModel\n",
    "│   ├── State transitions → validated input/output\n",
    "│   ├── Memory schema → pydantic-validated slots\n",
    "│   └── Persistent state handling with serialization\n",
    "└── Runnable interfaces → schema-driven pipelines\n",
    "\n",
    "🧪 11. Testing & Debugging in Agentic AI\n",
    "│\n",
    "├── Validate simulated tool inputs\n",
    "├── Unit testing for BaseModel tool schemas\n",
    "├── model_dump() for internal state inspection\n",
    "└── Test cases for multi-agent interactions\n",
    "\n",
    "🎓 12. Real-World Agentic AI Examples\n",
    "│\n",
    "├── Tool input validation (e.g., search query schema)\n",
    "├── Multi-input schema for LangGraph planner\n",
    "├── Dynamic function calling validation\n",
    "├── Structured memory using BaseModel\n",
    "└── LangChain agent tool I/O with constraints\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 📘 **1. Core Understanding of Pydantic**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. Definition\n",
    "\n",
    "**Pydantic v2** is a Python library that provides runtime **data validation and parsing using type hints**. It's built on a fast core (`pydantic-core`) and is widely used for defining structured data models with strict validation.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 2. Built-in Functions (Essentials Only)\n",
    "\n",
    "| Function                | Description                                                       |\n",
    "| ----------------------- | ----------------------------------------------------------------- |\n",
    "| `BaseModel`             | Base class to define schemas                                      |\n",
    "| `.model_validate(data)` | Validates and parses data into a model instance                   |\n",
    "| `.model_dump()`         | Serializes model data into a dictionary                           |\n",
    "| `.model_dump_json()`    | Serializes model into JSON                                        |\n",
    "| `.model_copy()`         | Copies the model (optionally with updates)                        |\n",
    "| `ConfigDict`            | Used to configure model behavior like `frozen`, `extra`, `strict` |\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 3. Use in Generative AI & Agentic AI (LangChain / LangGraph)\n",
    "\n",
    "| Where it's used                | Description                                                    |\n",
    "| ------------------------------ | -------------------------------------------------------------- |\n",
    "| ✅ Tool Input Schemas           | Define tool input structure using `@tool(args_schema=MyModel)` |\n",
    "| ✅ Output Parsing               | Use BaseModel to parse structured outputs from LLMs            |\n",
    "| ✅ Agent State Models           | LangGraph state is represented as BaseModel subclass           |\n",
    "| ✅ Memory Tracking              | Structured memory slots validated using BaseModel              |\n",
    "| ✅ Dynamic LLM Function Calling | Enables strict validation of function arguments passed by LLMs |\n",
    "\n",
    "---\n",
    "\n",
    "### 🌐 4. Real-Time Use Case\n",
    "\n",
    "A **LangChain agent** powered by GPT-4 needs to use a weather API tool. The tool expects inputs like `city: str` and `unit: str`. Pydantic ensures the LLM provides valid values, and rejects invalid calls like `city: 123`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 5. Code Example (LangChain Tool Input Schema)\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import tool\n",
    "\n",
    "# ✅ Define schema using Pydantic\n",
    "class WeatherToolInput(BaseModel):\n",
    "    city: str = Field(..., description=\"City name to get weather for\")\n",
    "    unit: str = Field(default=\"Celsius\", description=\"Temperature unit\")\n",
    "\n",
    "# ✅ Attach schema to a tool\n",
    "@tool(args_schema=WeatherToolInput)\n",
    "def get_weather(city: str, unit: str = \"Celsius\") -> str:\n",
    "    return f\"The weather in {city} is 28° {unit}\"\n",
    "\n",
    "# ✅ Now GPT or LangGraph agent can use it with structured validation\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 📦 **2. BaseModel (Backbone of AI Tool Schemas)**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. Definition\n",
    "\n",
    "`BaseModel` is the **core class** in Pydantic v2 used to define **typed and validated data models**.\n",
    "It auto-parses input types, applies constraints, and enables structured data for tools, agents, chains, and memory.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 2. Built-in Functions & Configs\n",
    "\n",
    "| Method / Config        | Description                                                         |\n",
    "| ---------------------- | ------------------------------------------------------------------- |\n",
    "| `BaseModel()`          | Create a new model with validated data                              |\n",
    "| `.model_validate(obj)` | Parses and validates external input                                 |\n",
    "| `.model_dump()`        | Converts the model to a Python dict                                 |\n",
    "| `.model_dump_json()`   | Serializes the model as JSON string                                 |\n",
    "| `.model_copy()`        | Returns a new copy (with optional overrides)                        |\n",
    "| `ConfigDict`           | Allows customizing behavior (e.g., `frozen=True`, `extra='forbid'`) |\n",
    "| `.model_config`        | Per-model configuration dictionary                                  |\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 3. When & Where Used (LangChain + LangGraph)\n",
    "\n",
    "| Use Case Area        | Description                                              |\n",
    "| -------------------- | -------------------------------------------------------- |\n",
    "| ✅ LangChain Tools    | Used to define `args_schema` for @tool decorators        |\n",
    "| ✅ Agent Tool Calling | Structures input/output for LLM tool usage               |\n",
    "| ✅ LangGraph State    | State classes inherit from BaseModel                     |\n",
    "| ✅ Agent Memory       | Defines slot structures with type safety                 |\n",
    "| ✅ Output Parsers     | Used to auto-parse LLM responses into structured formats |\n",
    "\n",
    "---\n",
    "\n",
    "### 🌐 4. Real-Time Use Case\n",
    "\n",
    "You’re building a **LangGraph support agent**. Its memory state includes:\n",
    "\n",
    "* `user_email: str`\n",
    "* `issue_type: str`\n",
    "* `priority: Optional[str]`\n",
    "\n",
    "By subclassing `BaseModel`, the state is validated every step in the graph, ensuring data consistency and agent robustness.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 5. Full Code Implementation\n",
    "\n",
    "#### ✅ Example 1: LangChain Tool Input Schema\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import tool\n",
    "\n",
    "class MathInput(BaseModel):\n",
    "    x: int = Field(..., description=\"First number\")\n",
    "    y: int = Field(..., description=\"Second number\")\n",
    "\n",
    "@tool(args_schema=MathInput)\n",
    "def add(x: int, y: int) -> int:\n",
    "    return x + y\n",
    "\n",
    "# LangChain will validate inputs passed from LLM before running the tool\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 2: LangGraph Agent State\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define agent memory/state\n",
    "class SupportState(BaseModel):\n",
    "    user_email: str\n",
    "    issue_type: str\n",
    "    priority: str = \"normal\"\n",
    "\n",
    "# Define a dummy node that handles state\n",
    "def log_issue(state: SupportState) -> SupportState:\n",
    "    print(f\"Received issue from {state.user_email}\")\n",
    "    return state\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(SupportState)\n",
    "builder.add_node(\"log\", log_issue)\n",
    "builder.set_entry_point(\"log\")\n",
    "builder.set_finish_point(\"log\")\n",
    "\n",
    "graph = builder.compile()\n",
    "graph.invoke(SupportState(user_email=\"john@example.com\", issue_type=\"login\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Bonus Config: Frozen State Example (Prevents Mutation)\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "\n",
    "class FrozenState(BaseModel):\n",
    "    model_config = ConfigDict(frozen=True)\n",
    "    name: str\n",
    "\n",
    "state = FrozenState(name=\"agent\")\n",
    "# state.name = \"updated\"  # ❌ Raises error: cannot modify frozen model\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 📄 **3. Model Fields (Types, Constraints, and Metadata)**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. Definition\n",
    "\n",
    "**Model Fields** in Pydantic are **typed attributes** inside a `BaseModel` that define:\n",
    "\n",
    "* the structure,\n",
    "* constraints (like `min_length`, `ge`, etc.),\n",
    "* defaults,\n",
    "* and documentation metadata (like `description`, `examples`).\n",
    "\n",
    "They are declared using:\n",
    "\n",
    "```python\n",
    "from pydantic import Field\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 2. Built-in Functions & Field Options\n",
    "\n",
    "| Feature          | Example                                      | Description                           |\n",
    "| ---------------- | -------------------------------------------- | ------------------------------------- |\n",
    "| `Field(...)`     | `name: str = Field(...)`                     | Required field                        |\n",
    "| `default=`       | `count: int = Field(0)`                      | Optional with default                 |\n",
    "| `description=`   | `Field(..., description=\"Enter your email\")` | Tool/prompt metadata                  |\n",
    "| `ge=0`, `le=100` | `score: int = Field(..., ge=0, le=100)`      | Numeric constraints                   |\n",
    "| `min_length=3`   | `name: str = Field(..., min_length=3)`       | String length constraint              |\n",
    "| `alias=`         | `Field(..., alias=\"userId\")`                 | Alternate name (e.g., for LLM output) |\n",
    "| `examples=`      | `Field(..., examples=[\"foo\"])`               | Used for UI or prompting context      |\n",
    "\n",
    "👉 Works with: `str`, `int`, `float`, `bool`, `list`, `dict`, `Optional[]`, `Literal`, `Annotated`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 3. When & Where Used (LangChain + LangGraph)\n",
    "\n",
    "| Use Case                 | Description                                                        |\n",
    "| ------------------------ | ------------------------------------------------------------------ |\n",
    "| ✅ Tool Parameters        | Define expected inputs (type, required/optional, docs)             |\n",
    "| ✅ LangGraph State Fields | Define memory/state variables and constraints                      |\n",
    "| ✅ Output Parsers         | Describe the fields to expect from LLM output                      |\n",
    "| ✅ Tool Metadata          | Enhance tool discoverability by LLM with `description`, `examples` |\n",
    "| ✅ Prompt Templates       | Fields injected into prompts with type safety and doc hints        |\n",
    "\n",
    "---\n",
    "\n",
    "### 🌐 4. Real-Time Use Case\n",
    "\n",
    "You're building a **Document Search tool** in LangChain. The tool accepts a query and number of results. You want to:\n",
    "\n",
    "* Require `query: str`\n",
    "* Limit `top_k: int` to values between 1 and 10\n",
    "\n",
    "This can be safely defined using `Field(..., ge=1, le=10)`, so the agent doesn't hallucinate an invalid value like -5 or 100.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 5. Full Code Implementation\n",
    "\n",
    "#### ✅ Example 1: LangChain Tool Input Fields with Constraints\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import tool\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(..., description=\"Search query string\")\n",
    "    top_k: int = Field(5, ge=1, le=10, description=\"Number of top results (1–10)\")\n",
    "\n",
    "@tool(args_schema=SearchInput)\n",
    "def search(query: str, top_k: int) -> str:\n",
    "    return f\"Searching '{query}' and returning top {top_k} results.\"\n",
    "\n",
    "# LLM will be forced to use only valid values\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 2: LangGraph State with Field Metadata\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TicketState(BaseModel):\n",
    "    email: str = Field(..., description=\"Customer email ID\")\n",
    "    issue: str = Field(..., min_length=10, description=\"Detailed issue description\")\n",
    "    priority: str = Field(default=\"normal\", description=\"Priority level\")\n",
    "\n",
    "# LangGraph will enforce these field rules at every step\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 3: Field Aliasing for Prompt Format\n",
    "\n",
    "```python\n",
    "class InputModel(BaseModel):\n",
    "    user_id: str = Field(..., alias=\"userId\", description=\"Unique ID of the user\")\n",
    "\n",
    "# If LLM response returns {\"userId\": \"abc123\"}, it maps to `user_id` in the model\n",
    "parsed = InputModel.model_validate({\"userId\": \"abc123\"})\n",
    "print(parsed.user_id)  # ✅ abc123\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary\n",
    "\n",
    "| What Fields Help You Do | How It Helps in GenAI                 |\n",
    "| ----------------------- | ------------------------------------- |\n",
    "| Constrain inputs        | Prevent LLM errors/hallucination      |\n",
    "| Add metadata            | Better prompt injection and UI        |\n",
    "| Enforce types           | Safe execution in LangGraph/LangChain |\n",
    "| Default/Optional logic  | Build flexible agents                 |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🎯 **4. Validation in Pydantic v2**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. Definition\n",
    "\n",
    "**Validation** in Pydantic is the process of checking whether the data conforms to type constraints, field rules, and custom logic.\n",
    "Pydantic v2 allows:\n",
    "\n",
    "* Built-in validation (via `Field`)\n",
    "* Advanced validation (via decorators like `@field_validator` and `@model_validator`)\n",
    "\n",
    "This ensures agents/tools **never operate on invalid inputs**, and **LLMs are held accountable**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 2. Built-in Functions & Validators\n",
    "\n",
    "#### 🔹 Field-Level Validators\n",
    "\n",
    "```python\n",
    "@field_validator(\"field_name\", mode=\"before\" or \"after\")\n",
    "def validate_field(cls, value): ...\n",
    "```\n",
    "\n",
    "| Parameter                | Description                   |\n",
    "| ------------------------ | ----------------------------- |\n",
    "| `field_name`             | Name of the field to validate |\n",
    "| `mode=\"before\"`          | Runs before type coercion     |\n",
    "| `mode=\"after\"` (default) | Runs after coercion           |\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔹 Model-Level Validators\n",
    "\n",
    "```python\n",
    "@model_validator(mode=\"before\" or \"after\")\n",
    "def validate_model(cls, values): ...\n",
    "```\n",
    "\n",
    "\\| Use case | Combine or cross-validate multiple fields |\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔹 Built-in Field Constraints (via `Field`)\n",
    "\n",
    "* `min_length`, `max_length`, `ge`, `le`, `regex`\n",
    "* `literal`, `enum`, `optional`\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 3. When & Where Used (LangChain + LangGraph)\n",
    "\n",
    "| Use Case                | Description                                       |\n",
    "| ----------------------- | ------------------------------------------------- |\n",
    "| ✅ Tool Input Validation | Prevent invalid agent inputs (e.g., empty search) |\n",
    "| ✅ Cross-Field Logic     | e.g., `if x == \"A\" then y must be True`           |\n",
    "| ✅ Memory Checks         | Ensure state variables are consistent             |\n",
    "| ✅ Tool Trigger Safety   | Only allow tool execution if inputs are correct   |\n",
    "| ✅ Prompt Guards         | Validate prompt response before use               |\n",
    "\n",
    "---\n",
    "\n",
    "### 🌐 4. Real-Time Use Case\n",
    "\n",
    "You have a tool in LangChain to **generate meeting links**.\n",
    "\n",
    "* If `platform == \"Zoom\"` → `email` is required.\n",
    "  You use a **model validator** to enforce this logic, preventing GPT-4 from skipping required values when calling tools.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 5. Full Code Implementation\n",
    "\n",
    "#### ✅ Example 1: Field Validator (after LLM input)\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from langchain.tools import tool\n",
    "\n",
    "class EmailInput(BaseModel):\n",
    "    email: str = Field(..., description=\"User email\")\n",
    "\n",
    "    @field_validator(\"email\")\n",
    "    def check_email_format(cls, v):\n",
    "        if \"@\" not in v:\n",
    "            raise ValueError(\"Invalid email format\")\n",
    "        return v\n",
    "\n",
    "@tool(args_schema=EmailInput)\n",
    "def send_invite(email: str):\n",
    "    return f\"Invite sent to {email}\"\n",
    "```\n",
    "\n",
    "🧠 GPT can’t call this tool without a valid `email@domain.com`.\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 2: Model Validator (Cross-field)\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "\n",
    "class MeetingInput(BaseModel):\n",
    "    platform: str = Field(..., description=\"Platform (Zoom or Teams)\")\n",
    "    email: str | None = Field(None, description=\"Required if Zoom\")\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_zoom_email(cls, values):\n",
    "        if values.platform == \"Zoom\" and not values.email:\n",
    "            raise ValueError(\"Email is required for Zoom meetings\")\n",
    "        return values\n",
    "```\n",
    "\n",
    "🛡️ Used inside LangGraph step or LangChain tool, this prevents LLM from triggering invalid logic.\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 3: Before-Mode Validator (Raw Input Cleaning)\n",
    "\n",
    "```python\n",
    "class UserInput(BaseModel):\n",
    "    name: str\n",
    "\n",
    "    @field_validator(\"name\", mode=\"before\")\n",
    "    def strip_whitespace(cls, v):\n",
    "        return v.strip()\n",
    "```\n",
    "\n",
    "🧼 Useful for cleaning prompt responses from LLMs.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary Table\n",
    "\n",
    "| Type                    | Purpose                | Use in GenAI                    |\n",
    "| ----------------------- | ---------------------- | ------------------------------- |\n",
    "| `@field_validator`      | Field-level checks     | Validate individual tool params |\n",
    "| `@model_validator`      | Cross-field validation | Validate full tool input state  |\n",
    "| Constraints via `Field` | Quick validation       | Auto-limit LLM/tool usage       |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🧬 **5. Model Composition in Pydantic v2**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. Definition\n",
    "\n",
    "**Model Composition** in Pydantic refers to combining models together using:\n",
    "\n",
    "* **Inheritance** (reusability),\n",
    "* **Nested models** (structured inputs/outputs),\n",
    "* **Recursive models** (self-referencing),\n",
    "* and **Generic models** (optional, advanced pattern).\n",
    "\n",
    "These techniques are essential when you need to build **multi-field states** or **tool schemas that contain other schemas** — like nested dictionaries with validation.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 2. Built-in Features\n",
    "\n",
    "| Feature             | Syntax                    | Description                                              |\n",
    "| ------------------- | ------------------------- | -------------------------------------------------------- |\n",
    "| 🔁 Inheritance      | `class B(A)`              | Reuse base schemas                                       |\n",
    "| 📦 Nested models    | Field with model type     | Validate deeply structured inputs                        |\n",
    "| 🔁 Recursive models | `Optional[List['Model']]` | Self-referencing chains (requires update\\_forward\\_refs) |\n",
    "| 🔢 Generics         | `GenericModel[T]`         | Template-like data models                                |\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 3. When & Where Used (LangChain + LangGraph)\n",
    "\n",
    "| Use Case           | Description                                                          |\n",
    "| ------------------ | -------------------------------------------------------------------- |\n",
    "| ✅ Tool Composition | A tool input model contains another model                            |\n",
    "| ✅ Agent Memory     | Store memory as nested object (e.g., user profile, chat history)     |\n",
    "| ✅ LangGraph State  | Model state with deeply structured properties                        |\n",
    "| ✅ Planner Outputs  | Reasoning chains return a list of nested task models                 |\n",
    "| ✅ Output Parsing   | LLM output parsed into multiple nested sections (metadata + content) |\n",
    "\n",
    "---\n",
    "\n",
    "### 🌐 4. Real-Time Use Case\n",
    "\n",
    "You’re building a **LangGraph Planner Agent**.\n",
    "\n",
    "* The planner returns a list of steps.\n",
    "* Each step contains a tool name and its arguments, which may themselves be structured.\n",
    "\n",
    "Using **nested models and recursive composition**, you can model this plan in a clean, validated form.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 5. Full Code Implementation\n",
    "\n",
    "#### ✅ Example 1: Nested Model (Tool Schema with sub-model)\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Coordinates(BaseModel):\n",
    "    latitude: float = Field(..., ge=-90, le=90)\n",
    "    longitude: float = Field(..., ge=-180, le=180)\n",
    "\n",
    "class LocationRequest(BaseModel):\n",
    "    city: str\n",
    "    coordinates: Coordinates\n",
    "\n",
    "# ✅ Tool schema or LangGraph state can now use LocationRequest directly\n",
    "data = {\n",
    "    \"city\": \"San Francisco\",\n",
    "    \"coordinates\": {\"latitude\": 37.77, \"longitude\": -122.42}\n",
    "}\n",
    "\n",
    "parsed = LocationRequest.model_validate(data)\n",
    "print(parsed.coordinates.latitude)  # 37.77\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 2: Inheritance for Shared Fields\n",
    "\n",
    "```python\n",
    "class BaseToolInput(BaseModel):\n",
    "    user_id: str\n",
    "    session_id: str\n",
    "\n",
    "class SearchToolInput(BaseToolInput):\n",
    "    query: str\n",
    "    top_k: int = 5\n",
    "```\n",
    "\n",
    "🧠 Useful for LangChain tools with common inputs (user/session tracking).\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 3: Recursive Model (for Planning or Graphs)\n",
    "\n",
    "```python\n",
    "from __future__ import annotations  # Required for self-reference\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Task(BaseModel):\n",
    "    name: str\n",
    "    subtasks: Optional[List[Task]] = None\n",
    "\n",
    "# Needed to resolve forward references\n",
    "Task.model_rebuild()\n",
    "\n",
    "# Example input\n",
    "plan = {\n",
    "    \"name\": \"Build App\",\n",
    "    \"subtasks\": [\n",
    "        {\"name\": \"Design UI\"},\n",
    "        {\"name\": \"Write Backend\", \"subtasks\": [\n",
    "            {\"name\": \"Setup DB\"},\n",
    "            {\"name\": \"Create API\"}\n",
    "        ]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "parsed = Task.model_validate(plan)\n",
    "print(parsed.subtasks[1].subtasks[0].name)  # Setup DB\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 4: LangGraph State with Nested Memory\n",
    "\n",
    "```python\n",
    "class UserMemory(BaseModel):\n",
    "    email: str\n",
    "    preferences: dict\n",
    "\n",
    "class AgentState(BaseModel):\n",
    "    user: UserMemory\n",
    "    current_task: str\n",
    "```\n",
    "\n",
    "🔁 Can be serialized, validated, and passed across nodes in LangGraph.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary\n",
    "\n",
    "| Composition Type         | Use in GenAI                        |\n",
    "| ------------------------ | ----------------------------------- |\n",
    "| Nested Models            | Tool inputs with sub-fields         |\n",
    "| Inheritance              | Shared tool inputs or agent context |\n",
    "| Recursive Models         | Planning trees or toolchains        |\n",
    "| Composition + Validation | Structuring LangGraph state trees   |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 📤 **6. Serialization & Deserialization in Pydantic v2**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. Definition\n",
    "\n",
    "**Serialization** is the process of converting a Pydantic model to a `dict` or `JSON` string so it can be passed between agents, saved to memory, or logged.\n",
    "\n",
    "**Deserialization** is converting external data (LLM output, tool input, memory state) into a validated model.\n",
    "\n",
    "In Pydantic v2, this is done through:\n",
    "\n",
    "* `.model_dump()`\n",
    "* `.model_dump_json()`\n",
    "* `.model_validate()`\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 2. Built-in Functions & Methods\n",
    "\n",
    "| Function                   | Purpose                                      |\n",
    "| -------------------------- | -------------------------------------------- |\n",
    "| `model_dump()`             | Serialize model → Python `dict`              |\n",
    "| `model_dump_json()`        | Serialize model → `JSON` string              |\n",
    "| `model_validate(data)`     | Parse dict/JSON → Model with validation      |\n",
    "| `model_copy(update={...})` | Clone model with optional updates            |\n",
    "| `@field_serializer`        | Customize how specific fields are serialized |\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 3. When & Where Used (LangChain + LangGraph)\n",
    "\n",
    "| Area                     | Purpose                                       |\n",
    "| ------------------------ | --------------------------------------------- |\n",
    "| ✅ LangGraph State Memory | Persist and restore agent state between steps |\n",
    "| ✅ LLM Tool Calls         | Convert tool output to JSON or dict           |\n",
    "| ✅ Input Parsing          | Convert LLM raw output → structured model     |\n",
    "| ✅ Debugging              | Log and visualize the model                   |\n",
    "| ✅ Prompt Templates       | Inject data into structured prompts           |\n",
    "| ✅ OutputParser           | Use model to validate and parse LLM outputs   |\n",
    "\n",
    "---\n",
    "\n",
    "### 🌐 4. Real-Time Use Case\n",
    "\n",
    "A LangGraph agent must pass state between nodes in JSON format. You need to:\n",
    "\n",
    "* Dump the current memory state before saving it.\n",
    "* Validate the restored state before reusing it.\n",
    "\n",
    "This guarantees the state is never corrupted or malformed during execution.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 5. Full Code Implementation\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 1: Serializing a LangGraph Agent State\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class AgentState(BaseModel):\n",
    "    user_id: str\n",
    "    current_step: str\n",
    "    context: dict = Field(default_factory=dict)\n",
    "\n",
    "# Create instance\n",
    "state = AgentState(user_id=\"U123\", current_step=\"fetch\")\n",
    "\n",
    "# Serialize to dict (e.g., for memory save or prompt inject)\n",
    "as_dict = state.model_dump()\n",
    "print(as_dict)\n",
    "\n",
    "# Serialize to JSON (e.g., send to external service or frontend)\n",
    "as_json = state.model_dump_json()\n",
    "print(as_json)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 2: Deserialization from Input (LLM Output)\n",
    "\n",
    "```python\n",
    "data = {\n",
    "    \"user_id\": \"U123\",\n",
    "    \"current_step\": \"fetch\",\n",
    "    \"context\": {\"intent\": \"weather\"}\n",
    "}\n",
    "\n",
    "validated_state = AgentState.model_validate(data)\n",
    "print(validated_state.context[\"intent\"])  # ✅ weather\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 3: Custom Serialization of a Field\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field, field_serializer\n",
    "from datetime import datetime\n",
    "\n",
    "class TimeStampedOutput(BaseModel):\n",
    "    response: str\n",
    "    timestamp: datetime = Field(default_factory=datetime.utcnow)\n",
    "\n",
    "    @field_serializer(\"timestamp\")\n",
    "    def format_time(cls, v):\n",
    "        return v.isoformat()\n",
    "\n",
    "output = TimeStampedOutput(response=\"Done\")\n",
    "print(output.model_dump())  # Timestamp will be in ISO format\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 4: LangChain OutputParser Using Pydantic Model\n",
    "\n",
    "```python\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class ResponseModel(BaseModel):\n",
    "    answer: str\n",
    "    confidence: float\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ResponseModel)\n",
    "\n",
    "# Example LLM response\n",
    "raw = '{\"answer\": \"Yes\", \"confidence\": 0.91}'\n",
    "parsed = parser.parse(raw)\n",
    "print(parsed.answer)  # ✅ \"Yes\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary Table\n",
    "\n",
    "| Method              | Usage in GenAI                                        |\n",
    "| ------------------- | ----------------------------------------------------- |\n",
    "| `model_dump()`      | Save LangGraph state / inject into prompt             |\n",
    "| `model_dump_json()` | Persist to Redis or remote DB                         |\n",
    "| `model_validate()`  | Ingest tool input or LLM output safely                |\n",
    "| `@field_serializer` | Customize serialization of timestamps, decimals, etc. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🛡️ **7. Strict Mode & Type Safety in Pydantic v2**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. Definition\n",
    "\n",
    "**Strict Mode and Type Safety** in Pydantic v2 enforce that **inputs match exactly the expected types** — no coercion allowed.\n",
    "\n",
    "🔒 For example:\n",
    "\n",
    "* `\"5\"` won’t be accepted as an `int`\n",
    "* `None` won’t be accepted unless declared as `Optional[...]`\n",
    "\n",
    "This is **vital in Agentic AI** to prevent LLMs from “hallucinating” valid-looking, but **structurally invalid** tool inputs or state.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 2. Built-in Tools & Configurations\n",
    "\n",
    "| Feature                                      | Description                                                     |\n",
    "| -------------------------------------------- | --------------------------------------------------------------- |\n",
    "| `StrictStr`, `StrictInt`, `StrictBool`, etc. | Accept only exact types                                         |\n",
    "| `ConfigDict(strict=True)`                    | Enforce strict mode globally on the model                       |\n",
    "| `extra='forbid'`                             | Disallow extra fields                                           |\n",
    "| `frozen=True`                                | Make models immutable                                           |\n",
    "| `allow_inf_nan=False`                        | Disallow `NaN` or `Infinity`                                    |\n",
    "| `model_config`                               | Local model-level configuration (instead of class Config in v1) |\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 3. When & Where Used (LangChain + LangGraph)\n",
    "\n",
    "| Use Case                      | Description                                                   |\n",
    "| ----------------------------- | ------------------------------------------------------------- |\n",
    "| ✅ Tool Input Validation       | Block malformed inputs like `\"5\"` for an `int`                |\n",
    "| ✅ LangGraph State Consistency | Prevent LLM or user logic from injecting extra or bad data    |\n",
    "| ✅ Agent Tool-Safety           | Harden tools against bad LLM behavior                         |\n",
    "| ✅ Critical Steps              | Use strict types for financial, scheduling, or security tasks |\n",
    "| ✅ Memory Mutability           | Use `frozen=True` to prevent unwanted state changes mid-run   |\n",
    "\n",
    "---\n",
    "\n",
    "### 🌐 4. Real-Time Use Case\n",
    "\n",
    "Your LLM planner agent returns `\"10\"` as a string for a `page_count: int` tool input.\n",
    "\n",
    "Without strict mode, this may be coerced and silently accepted.\n",
    "With strict mode, it will raise a validation error — forcing your system to either correct or reject the invalid LLM behavior.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 5. Full Code Implementation\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 1: Enforcing Strict Types\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, StrictInt, StrictStr\n",
    "\n",
    "class ToolInput(BaseModel):\n",
    "    query: StrictStr\n",
    "    count: StrictInt  # 👈 Must be int, not string\n",
    "\n",
    "# Valid input\n",
    "ToolInput.model_validate({\"query\": \"LLM safety\", \"count\": 5})  # ✅\n",
    "\n",
    "# Invalid input (LLM returns string)\n",
    "ToolInput.model_validate({\"query\": \"test\", \"count\": \"5\"})  \n",
    "# ❌ ValidationError: value is not a valid integer\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 2: Strict Model Config\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "\n",
    "class SecureState(BaseModel):\n",
    "    model_config = ConfigDict(strict=True, extra='forbid')  # 👈 Enforce strict mode globally\n",
    "    step: int\n",
    "    user: str\n",
    "\n",
    "# Invalid extra field\n",
    "SecureState.model_validate({\"step\": 1, \"user\": \"Alice\", \"bad_field\": \"oops\"})\n",
    "# ❌ Error: Extra fields not permitted\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 3: Frozen Models for LangGraph State\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "\n",
    "class FrozenAgentState(BaseModel):\n",
    "    model_config = ConfigDict(frozen=True)\n",
    "    user_id: str\n",
    "    task: str\n",
    "\n",
    "state = FrozenAgentState(user_id=\"U123\", task=\"fetch\")\n",
    "# state.task = \"update\"  # ❌ TypeError: Cannot assign to frozen model\n",
    "```\n",
    "\n",
    "🔐 Ensures the agent’s state is **immutable** during execution.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary Table\n",
    "\n",
    "| Feature                  | Why It Matters in GenAI                |\n",
    "| ------------------------ | -------------------------------------- |\n",
    "| `StrictStr`, `StrictInt` | Blocks unsafe coercion from LLM inputs |\n",
    "| `strict=True`            | Ensures no hidden errors slip in       |\n",
    "| `extra='forbid'`         | Prevents hallucinated inputs           |\n",
    "| `frozen=True`            | Makes memory/state read-only           |\n",
    "| `allow_inf_nan=False`    | Ensures mathematical safety            |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🔗 **8. Advanced Features in Pydantic v2**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. Definition\n",
    "\n",
    "Pydantic v2 offers several advanced features that allow you to:\n",
    "\n",
    "* Dynamically switch between model types (Union/Discriminated Unions),\n",
    "* Store internal state or metadata (`PrivateAttr`),\n",
    "* Define read-only computed fields (`@computed_field`),\n",
    "* Introspect fields for dynamic tool wiring or graph routing.\n",
    "\n",
    "These are useful in **multi-agent routing**, **memory-controlled LangGraph edges**, and **adaptive agent state machines**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 2. Built-in Features & Functions\n",
    "\n",
    "| Feature                  | Purpose                                  | Syntax                                                   |\n",
    "| ------------------------ | ---------------------------------------- | -------------------------------------------------------- |\n",
    "| **Discriminated Unions** | Switch between model types using a field | `Literal[...]`, `discriminator=\"type\"`                   |\n",
    "| **Private Attributes**   | Store internal, non-serializable values  | `PrivateAttr()`                                          |\n",
    "| **Computed Fields**      | Create read-only dynamic fields          | `@computed_field(return_type=...)`                       |\n",
    "| **Introspection**        | Access model internals                   | `__pydantic_fields__`, `__annotations__`, `model_fields` |\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 3. When & Where Used (LangChain + LangGraph)\n",
    "\n",
    "| Use Case                  | Description                                                          |\n",
    "| ------------------------- | -------------------------------------------------------------------- |\n",
    "| ✅ Multi-Agent Routing     | Use Discriminated Union to define which agent to route to            |\n",
    "| ✅ LangGraph Memory        | Use PrivateAttr to track token count or LLM call logs                |\n",
    "| ✅ Read-only Metadata      | Computed fields like `created_at`, `step_count`, `token_budget_used` |\n",
    "| ✅ Conditional State Logic | Use model introspection to choose graph edge based on model content  |\n",
    "| ✅ Agent Type Handling     | Model different agent inputs/outputs using Union types               |\n",
    "\n",
    "---\n",
    "\n",
    "### 🌐 4. Real-Time Use Case\n",
    "\n",
    "In LangGraph, your memory state needs to support **two agent types**: `PlannerAgent` and `ToolAgent`.\n",
    "\n",
    "Using a **discriminated union**, LangGraph can route to the right node depending on the agent type field in the state.\n",
    "You also want to track the **token usage internally** (not serialized) using a `PrivateAttr`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 5. Full Code Implementation\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 1: Discriminated Union (Multi-Agent Routing)\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Union\n",
    "\n",
    "class PlannerAgent(BaseModel):\n",
    "    type: Literal[\"planner\"]\n",
    "    plan: str\n",
    "\n",
    "class ToolAgent(BaseModel):\n",
    "    type: Literal[\"tool\"]\n",
    "    tool_name: str\n",
    "    args: dict\n",
    "\n",
    "AgentState = Union[PlannerAgent, ToolAgent]  # 👈 Switches based on `type`\n",
    "\n",
    "# Validate incoming state\n",
    "raw = {\"type\": \"tool\", \"tool_name\": \"search\", \"args\": {\"query\": \"weather\"}}\n",
    "agent = ToolAgent.model_validate(raw)\n",
    "print(agent.tool_name)  # ✅ \"search\"\n",
    "```\n",
    "\n",
    "📌 In LangGraph, use this union to determine node logic dynamically.\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 2: Private Attribute (Non-Serialized State)\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, PrivateAttr\n",
    "\n",
    "class MemoryState(BaseModel):\n",
    "    user_id: str\n",
    "    _token_count: int = PrivateAttr(default=0)\n",
    "\n",
    "    def update_token_usage(self, tokens: int):\n",
    "        self._token_count += tokens\n",
    "\n",
    "state = MemoryState(user_id=\"U456\")\n",
    "state.update_token_usage(100)\n",
    "print(state._token_count)  # ✅ 100\n",
    "\n",
    "print(state.model_dump())  # ✅ No \"_token_count\" — it's private\n",
    "```\n",
    "\n",
    "🔒 Safe to use for tracking behind-the-scenes logic or metadata.\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 3: Computed Field (Read-only Metadata)\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, computed_field\n",
    "from datetime import datetime\n",
    "\n",
    "class UserState(BaseModel):\n",
    "    name: str\n",
    "\n",
    "    @computed_field(return_type=str)\n",
    "    def created_at(self) -> str:\n",
    "        return datetime.utcnow().isoformat()\n",
    "\n",
    "user = UserState(name=\"John\")\n",
    "print(user.created_at)  # ✅ Automatically generated timestamp\n",
    "```\n",
    "\n",
    "🔄 You can use this in LangGraph states to add runtime-only data like time, tokens, etc.\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 4: Model Introspection (For Dynamic Tool Creation)\n",
    "\n",
    "```python\n",
    "class ToolInput(BaseModel):\n",
    "    query: str\n",
    "    top_k: int = 5\n",
    "\n",
    "print(ToolInput.__pydantic_fields__.keys())  # dict_keys(['query', 'top_k'])\n",
    "\n",
    "# Useful for LangGraph dynamic node wiring\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary Table\n",
    "\n",
    "| Feature                | Benefit in GenAI / LangGraph           |\n",
    "| ---------------------- | -------------------------------------- |\n",
    "| `Discriminated Unions` | Dynamically switch agent/tool types    |\n",
    "| `PrivateAttr`          | Store runtime-only info (tokens, time) |\n",
    "| `@computed_field`      | Add derived read-only fields           |\n",
    "| `__pydantic_fields__`  | Enable graph and tool introspection    |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 📚 **9. Error Handling in Pydantic v2**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. Definition\n",
    "\n",
    "**Error Handling** in Pydantic ensures that any **invalid, malformed, or unexpected input** gets caught with clear, structured error messages.\n",
    "Pydantic raises a `ValidationError` whenever data fails to meet the model’s rules — and you can catch, inspect, or log it.\n",
    "\n",
    "This is essential for:\n",
    "\n",
    "* 🛡️ Preventing LangChain tools from silently failing\n",
    "* 🔁 Implementing retries in LangGraph\n",
    "* 📬 Giving LLMs feedback when their output doesn't validate\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 2. Key Error Classes & Methods\n",
    "\n",
    "| Class / Method    | Description                                                     |\n",
    "| ----------------- | --------------------------------------------------------------- |\n",
    "| `ValidationError` | Raised on invalid `.model_validate()` calls                     |\n",
    "| `.errors()`       | Returns list of field-level error dicts                         |\n",
    "| `.error_count()`  | Returns number of errors                                        |\n",
    "| `.json()`         | Serializes the error as JSON (great for debugging/LLM feedback) |\n",
    "| `try/except`      | Catch validation issues in tool execution or LangGraph steps    |\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 3. When & Where Used (LangChain + LangGraph)\n",
    "\n",
    "| Use Case                | Description                                            |\n",
    "| ----------------------- | ------------------------------------------------------ |\n",
    "| ✅ Tool Call Input Guard | Catch bad LLM input before tool executes               |\n",
    "| ✅ LangGraph Node Safety | Prevent bad state updates or transitions               |\n",
    "| ✅ Retry Logic           | Detect failure and re-ask LLM for corrected output     |\n",
    "| ✅ Logging + Debugging   | Log error tracebacks for observability                 |\n",
    "| ✅ Feedback Loop         | Return schema error message to LLM for self-correction |\n",
    "\n",
    "---\n",
    "\n",
    "### 🌐 4. Real-Time Use Case\n",
    "\n",
    "You’re using a **LangChain Tool** that expects:\n",
    "\n",
    "```python\n",
    "{\"email\": \"user@example.com\", \"age\": 30}\n",
    "```\n",
    "\n",
    "But GPT mistakenly outputs:\n",
    "\n",
    "```python\n",
    "{\"email\": 1234, \"age\": \"old\"}\n",
    "```\n",
    "\n",
    "Instead of crashing, you use Pydantic’s validation to:\n",
    "\n",
    "* Catch the error\n",
    "* Print a user-friendly message\n",
    "* Retry the call or correct the LLM\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 5. Full Code Implementation\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 1: Basic Validation Error Catching\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "class UserInput(BaseModel):\n",
    "    email: str\n",
    "    age: int\n",
    "\n",
    "bad_input = {\"email\": 1234, \"age\": \"old\"}\n",
    "\n",
    "try:\n",
    "    validated = UserInput.model_validate(bad_input)\n",
    "except ValidationError as e:\n",
    "    print(\"⚠️ Validation failed!\")\n",
    "    print(e.errors())  # List of errors\n",
    "    print(e.json())    # JSON string (useful for LLM feedback)\n",
    "```\n",
    "\n",
    "🧠 This allows you to **catch malformed tool inputs** before execution.\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 2: Use Inside LangChain Tool\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel, ValidationError, Field\n",
    "\n",
    "class WeatherInput(BaseModel):\n",
    "    city: str = Field(..., description=\"City to search\")\n",
    "    unit: str = Field(default=\"Celsius\")\n",
    "\n",
    "@tool(args_schema=WeatherInput)\n",
    "def get_weather(city: str, unit: str = \"Celsius\") -> str:\n",
    "    return f\"Weather in {city} is 25° {unit}\"\n",
    "\n",
    "# Simulate tool call from LLM\n",
    "raw_input = {\"city\": 999}  # invalid input\n",
    "\n",
    "try:\n",
    "    validated = WeatherInput.model_validate(raw_input)\n",
    "    print(get_weather(**validated.model_dump()))\n",
    "except ValidationError as e:\n",
    "    print(\"🛑 GPT provided invalid tool input:\")\n",
    "    print(e.errors())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Example 3: LangGraph Retry Logic with Validation\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "class AgentState(BaseModel):\n",
    "    query: str\n",
    "\n",
    "def validate_and_continue(state: dict):\n",
    "    try:\n",
    "        valid = AgentState.model_validate(state)\n",
    "        return valid\n",
    "    except ValidationError as e:\n",
    "        print(\"🧠 Retry needed due to invalid state:\", e.errors())\n",
    "        return {\"query\": \"DEFAULT\"}  # Or retry node logic\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"check\", validate_and_continue)\n",
    "graph.set_entry_point(\"check\")\n",
    "graph.set_finish_point(\"check\")\n",
    "graph = graph.compile()\n",
    "\n",
    "graph.invoke({\"query\": 123})  # Invalid query triggers fallback logic\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary Table\n",
    "\n",
    "| Feature           | Benefit in GenAI                           |\n",
    "| ----------------- | ------------------------------------------ |\n",
    "| `ValidationError` | Catch invalid LLM input or state           |\n",
    "| `.errors()`       | Inspect what went wrong field-by-field     |\n",
    "| `.json()`         | Use error in LLM feedback prompts          |\n",
    "| Retry logic       | Ask LLM to regenerate with corrected input |\n",
    "| Logging           | Debug tool failures in LangGraph pipelines |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🔁 **10. Integration with LangChain and LangGraph**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. Definition\n",
    "\n",
    "This section explains **how Pydantic v2 is deeply integrated** with:\n",
    "\n",
    "* 🔧 LangChain tools\n",
    "* 🧠 LangGraph state machines\n",
    "* 🪄 Output parsers and memory handlers\n",
    "* 🧩 LLM function calling & schema validation\n",
    "\n",
    "Pydantic acts as the **schema backbone** for input validation, memory consistency, and safe execution paths in AI agents.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 2. Pydantic Roles in LangChain & LangGraph\n",
    "\n",
    "| Layer                    | Usage                                                        |\n",
    "| ------------------------ | ------------------------------------------------------------ |\n",
    "| 🛠️ Tools                | `@tool(args_schema=YourModel)`                               |\n",
    "| 🗣️ LLM Function Calling | Auto-generated OpenAI function schemas                       |\n",
    "| 🧠 State Management      | LangGraph agent state = `BaseModel` subclass                 |\n",
    "| 📦 Output Parsing        | Use `PydanticOutputParser` to parse structured LLM responses |\n",
    "| 🪪 Memory                | Define structured memory with nested/composed models         |\n",
    "| 🔁 Retry & Feedback      | Catch `ValidationError` and trigger retry logic              |\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 3. Where It’s Used (In Practice)\n",
    "\n",
    "| Feature             | LangChain    | LangGraph                                  |\n",
    "| ------------------- | ------------ | ------------------------------------------ |\n",
    "| Tool input schema   | ✅            | ✅                                          |\n",
    "| Tool return schema  | ✅ (custom)   | ✅                                          |\n",
    "| Agent memory/state  | ❌            | ✅ (core requirement)                       |\n",
    "| Output parser       | ✅            | ✅                                          |\n",
    "| Retry mechanism     | Limited      | ✅ (node logic or error flow)               |\n",
    "| Multi-agent planner | Experimental | ✅ (with discriminated unions + validators) |\n",
    "\n",
    "---\n",
    "\n",
    "### 🌐 4. Real-Time Use Case\n",
    "\n",
    "You're building a **LangGraph-based multi-agent system**:\n",
    "\n",
    "1. The `Planner` agent decides the next step.\n",
    "2. The plan is validated with a Pydantic model.\n",
    "3. If the plan is invalid, LangGraph retries.\n",
    "4. A downstream `ToolExecutor` uses `@tool(args_schema=YourInputModel)` to execute tools.\n",
    "5. The tool result is validated again and stored in structured memory (BaseModel).\n",
    "\n",
    "This entire pipeline uses **only Pydantic** models for inputs, outputs, memory, retry, and edge routing.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 5. Full Code Integration Example\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Step 1: Define Tool Input Schema\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import tool\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(..., description=\"Search query\")\n",
    "    top_k: int = Field(default=5, ge=1, le=10)\n",
    "\n",
    "@tool(args_schema=SearchInput)\n",
    "def search_tool(query: str, top_k: int = 5) -> str:\n",
    "    return f\"Searching for {query} (top {top_k} results)\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Step 2: LangGraph State with Pydantic\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class AgentState(BaseModel):\n",
    "    step: str\n",
    "    memory: dict\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Step 3: Node with Pydantic Validation & Retry\n",
    "\n",
    "```python\n",
    "from pydantic import ValidationError\n",
    "\n",
    "def process_step(state: AgentState) -> AgentState:\n",
    "    try:\n",
    "        # Ensure memory contains valid keys\n",
    "        if \"query\" not in state.memory:\n",
    "            raise ValidationError(\"Missing query in memory\")\n",
    "        return state\n",
    "    except ValidationError as e:\n",
    "        print(\"❌ Invalid memory structure:\", e)\n",
    "        # Fix it or send to fallback edge\n",
    "        return AgentState(step=\"fallback\", memory={\"query\": \"default\"})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Step 4: Graph Wiring\n",
    "\n",
    "```python\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"process\", process_step)\n",
    "builder.set_entry_point(\"process\")\n",
    "builder.set_finish_point(\"process\")\n",
    "graph = builder.compile()\n",
    "\n",
    "graph.invoke(AgentState(step=\"start\", memory={}))  # Triggers retry logic\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Step 5: Output Parser with Pydantic\n",
    "\n",
    "```python\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class AnswerModel(BaseModel):\n",
    "    answer: str\n",
    "    confidence: float\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=AnswerModel)\n",
    "\n",
    "llm_response = '{\"answer\": \"42\", \"confidence\": 0.99}'\n",
    "parsed = parser.parse(llm_response)\n",
    "print(parsed.answer)  # ✅ 42\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary Diagram\n",
    "\n",
    "```text\n",
    "+-------------------+     Pydantic Model      +----------------------+\n",
    "|   LangChain Tool  | <--------------------> |     Input Schema     |\n",
    "+-------------------+                        +----------------------+\n",
    "        |\n",
    "        v\n",
    "+-------------------+                        +----------------------+\n",
    "|  LLM Function Call| <--------------------> |  JSON Function Spec  |\n",
    "+-------------------+                        +----------------------+\n",
    "        |\n",
    "        v\n",
    "+-------------------+                        +----------------------+\n",
    "| LangGraph Node    | <--------------------> |   AgentState (Model) |\n",
    "+-------------------+                        +----------------------+\n",
    "        |\n",
    "        v\n",
    "+-------------------+                        +----------------------+\n",
    "|  Output Parser    | <--------------------> |    Output Model      |\n",
    "+-------------------+                        +----------------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 🧪 **11. Testing & Debugging in Agentic AI (with Pydantic)**\n",
    "\n",
    "We’ll cover:\n",
    "\n",
    "1. ✅ How to **simulate tool inputs** for testing\n",
    "2. ✅ How to **unit test schemas** in isolation\n",
    "3. ✅ How to **inspect & debug state** using `.model_dump()`\n",
    "4. ✅ Best practices for **multi-agent test coverage**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
