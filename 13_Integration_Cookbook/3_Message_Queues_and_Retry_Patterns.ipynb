{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸ” Message Queues + Retry Patterns (Pydantic v2)\n",
    "\n",
    "### ğŸ¯ Intent\n",
    "\n",
    "Use **Pydantic v2** with Kafka / RabbitMQ / SQS / Redis for **validated payloads**, **idempotency**, **retries**, and **dead-letter handling**.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§© Core Components\n",
    "\n",
    "1. **ğŸ“¦ DTOs for Jobs**\n",
    "\n",
    "   * Define `JobIn / JobOut` models.\n",
    "   * Strong types: `UUID`, `AwareDatetime`, `Decimal`, `AnyUrl`.\n",
    "\n",
    "2. **ğŸ§ª Validate at Both Ends**\n",
    "\n",
    "   * Producer â†’ `job.model_dump_json(by_alias=True)` before enqueue.\n",
    "   * Consumer â†’ `Job.model_validate_json(msg)` or `TypeAdapter(list[Job])` for batches.\n",
    "   * Invalid â†’ move to **DLQ** with error metadata.\n",
    "\n",
    "3. **ğŸ†” Idempotency**\n",
    "\n",
    "   * Payload must include `id: UUID` or `idempotency_key`.\n",
    "   * Deduplicate with Redis SET (TTL) or DB unique constraint.\n",
    "\n",
    "4. **ğŸ” Retry Strategy**\n",
    "\n",
    "   * **Transient errors (5xx, timeouts)** â†’ retry with exponential backoff + jitter.\n",
    "   * **Permanent errors (validation, 4xx)** â†’ send to DLQ.\n",
    "   * Track attempts with `retries: int`.\n",
    "\n",
    "5. **â³ Backoff & Visibility**\n",
    "\n",
    "   * SQS â†’ extend visibility timeout if job is long.\n",
    "   * RabbitMQ â†’ delayed exchange.\n",
    "   * Kafka â†’ retry topics (`.retry.1m`, `.retry.5m`, etc.).\n",
    "\n",
    "6. **ğŸ’€ Dead-Letter Queue (DLQ)**\n",
    "\n",
    "   * Final stop for failed jobs. Store: payload, error, attempts, timestamp.\n",
    "   * Provide **replay tool** to re-publish after fixes.\n",
    "\n",
    "7. **ğŸ›¡ï¸ Safe Models**\n",
    "\n",
    "   * Use **discriminated unions** for multiple job types:\n",
    "\n",
    "     ```python\n",
    "     Task = Ingest | Notify | Reconcile\n",
    "     class Job(BaseModel):\n",
    "         task: Task = Field(..., discriminator=\"kind\")\n",
    "     ```\n",
    "   * Mask PII in logs with `@field_serializer`.\n",
    "\n",
    "8. **ğŸ“Š Observability**\n",
    "\n",
    "   * Metrics: accepted, retried, DLQâ€™d, latency per job type.\n",
    "   * Add `trace_id` / `span_id` to payload for tracing.\n",
    "\n",
    "9. **âš™ï¸ Ordering & Concurrency**\n",
    "\n",
    "   * Partition key = entity ID (Kafka) to keep order.\n",
    "   * Use consumer concurrency caps to prevent overload.\n",
    "\n",
    "10. **ğŸ§° Outbox & Inbox**\n",
    "\n",
    "* **Outbox**: write events in DB transaction â†’ worker publishes.\n",
    "* **Inbox**: store processed keys to block duplicates.\n",
    "\n",
    "11. **ğŸ§¾ Versioning**\n",
    "\n",
    "* Add `schema_version`.\n",
    "* Only additive changes.\n",
    "* Snapshot `model_json_schema()` to lock contract.\n",
    "\n",
    "12. **ğŸ§ª Testing**\n",
    "\n",
    "* Unit test DTOs with valid/invalid payloads.\n",
    "* Integration test consumer retries, DLQ flow, idempotency.\n",
    "\n",
    "13. **ğŸ” Security**\n",
    "\n",
    "* Donâ€™t embed secrets in messages â†’ send IDs, fetch server-side.\n",
    "* Encrypt sensitive fields if stored.\n",
    "* Scrub logs of PII.\n",
    "\n",
    "14. **âš¡ Performance**\n",
    "\n",
    "* Keep payloads flat & small.\n",
    "* Batch produce/consume where possible.\n",
    "* Reuse producer/consumer clients.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
