{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🔁 Message Queues + Retry Patterns (Pydantic v2)\n",
    "\n",
    "### 🎯 Intent\n",
    "\n",
    "Use **Pydantic v2** with Kafka / RabbitMQ / SQS / Redis for **validated payloads**, **idempotency**, **retries**, and **dead-letter handling**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 Core Components\n",
    "\n",
    "1. **📦 DTOs for Jobs**\n",
    "\n",
    "   * Define `JobIn / JobOut` models.\n",
    "   * Strong types: `UUID`, `AwareDatetime`, `Decimal`, `AnyUrl`.\n",
    "\n",
    "2. **🧪 Validate at Both Ends**\n",
    "\n",
    "   * Producer → `job.model_dump_json(by_alias=True)` before enqueue.\n",
    "   * Consumer → `Job.model_validate_json(msg)` or `TypeAdapter(list[Job])` for batches.\n",
    "   * Invalid → move to **DLQ** with error metadata.\n",
    "\n",
    "3. **🆔 Idempotency**\n",
    "\n",
    "   * Payload must include `id: UUID` or `idempotency_key`.\n",
    "   * Deduplicate with Redis SET (TTL) or DB unique constraint.\n",
    "\n",
    "4. **🔁 Retry Strategy**\n",
    "\n",
    "   * **Transient errors (5xx, timeouts)** → retry with exponential backoff + jitter.\n",
    "   * **Permanent errors (validation, 4xx)** → send to DLQ.\n",
    "   * Track attempts with `retries: int`.\n",
    "\n",
    "5. **⏳ Backoff & Visibility**\n",
    "\n",
    "   * SQS → extend visibility timeout if job is long.\n",
    "   * RabbitMQ → delayed exchange.\n",
    "   * Kafka → retry topics (`.retry.1m`, `.retry.5m`, etc.).\n",
    "\n",
    "6. **💀 Dead-Letter Queue (DLQ)**\n",
    "\n",
    "   * Final stop for failed jobs. Store: payload, error, attempts, timestamp.\n",
    "   * Provide **replay tool** to re-publish after fixes.\n",
    "\n",
    "7. **🛡️ Safe Models**\n",
    "\n",
    "   * Use **discriminated unions** for multiple job types:\n",
    "\n",
    "     ```python\n",
    "     Task = Ingest | Notify | Reconcile\n",
    "     class Job(BaseModel):\n",
    "         task: Task = Field(..., discriminator=\"kind\")\n",
    "     ```\n",
    "   * Mask PII in logs with `@field_serializer`.\n",
    "\n",
    "8. **📊 Observability**\n",
    "\n",
    "   * Metrics: accepted, retried, DLQ’d, latency per job type.\n",
    "   * Add `trace_id` / `span_id` to payload for tracing.\n",
    "\n",
    "9. **⚙️ Ordering & Concurrency**\n",
    "\n",
    "   * Partition key = entity ID (Kafka) to keep order.\n",
    "   * Use consumer concurrency caps to prevent overload.\n",
    "\n",
    "10. **🧰 Outbox & Inbox**\n",
    "\n",
    "* **Outbox**: write events in DB transaction → worker publishes.\n",
    "* **Inbox**: store processed keys to block duplicates.\n",
    "\n",
    "11. **🧾 Versioning**\n",
    "\n",
    "* Add `schema_version`.\n",
    "* Only additive changes.\n",
    "* Snapshot `model_json_schema()` to lock contract.\n",
    "\n",
    "12. **🧪 Testing**\n",
    "\n",
    "* Unit test DTOs with valid/invalid payloads.\n",
    "* Integration test consumer retries, DLQ flow, idempotency.\n",
    "\n",
    "13. **🔐 Security**\n",
    "\n",
    "* Don’t embed secrets in messages → send IDs, fetch server-side.\n",
    "* Encrypt sensitive fields if stored.\n",
    "* Scrub logs of PII.\n",
    "\n",
    "14. **⚡ Performance**\n",
    "\n",
    "* Keep payloads flat & small.\n",
    "* Batch produce/consume where possible.\n",
    "* Reuse producer/consumer clients.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
