{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🧠 ML/ETL Config with Pydantic\n",
    "\n",
    "### 🎯 Intent\n",
    "\n",
    "Use **Pydantic v2** to define configs & schemas for ML/ETL pipelines → reproducible runs, clean inputs, early failures.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 Core Components\n",
    "\n",
    "1. **⚙️ Settings Layer**\n",
    "\n",
    "   * Centralize env configs with `BaseSettings`.\n",
    "   * Typical: `DATA_DIR: DirectoryPath`, `SEED: int`, `TRACKING_URL: AnyUrl`.\n",
    "   * Load via `.env`, env vars, `secrets_dir`.\n",
    "\n",
    "2. **🧱 Pipeline Config Models**\n",
    "\n",
    "   * Split configs per stage: `ExtractConfig`, `TransformConfig`, `TrainConfig`, `PredictConfig`.\n",
    "   * Nest inside `AppConfig`.\n",
    "\n",
    "3. **📊 Dataset Row Schema**\n",
    "\n",
    "   * Define row-level `BaseModel` with type/range/regex checks.\n",
    "   * Validate batches via `TypeAdapter(list[RowModel])`.\n",
    "\n",
    "4. **🏷️ Column Contracts**\n",
    "\n",
    "   * Use `Enum` / `Literal` for feature names (avoid typos).\n",
    "   * Map raw → canonical via `Field(alias=\"raw_col\")`.\n",
    "\n",
    "5. **🔢 Hyperparams as Types**\n",
    "\n",
    "   * `confloat(ge=0, le=1)` → learning rate.\n",
    "   * `conint(ge=1)` → depth.\n",
    "   * Discriminated unions for algo-specific configs (`algo=\"xgb\" | \"rf\"`).\n",
    "\n",
    "6. **📁 Paths & I/O**\n",
    "\n",
    "   * Use `Path`, `FilePath`, `DirectoryPath`, `AnyUrl`.\n",
    "   * Optional `@field_validator` to check existence.\n",
    "\n",
    "7. **🧪 Data Quality Guards**\n",
    "\n",
    "   * `@model_validator(mode=\"after\")`: check `start <= end`, no nulls, unique keys.\n",
    "   * Raise `PydanticCustomError` with clear codes.\n",
    "\n",
    "8. **🚀 Batch & Stream Validation**\n",
    "\n",
    "   * Batch → one adapter per chunk (fast).\n",
    "   * Stream → same schema for Kafka/SQS messages.\n",
    "\n",
    "9. **📤 Reproducibility**\n",
    "\n",
    "   * Save config dump (`model_dump_json`) + compute hash for lineage.\n",
    "   * Store with metrics/artifacts.\n",
    "\n",
    "10. **🧰 Schema Docs**\n",
    "\n",
    "* Publish `model_json_schema(by_alias=True)` for team contracts.\n",
    "* Snapshot-test schema for stability.\n",
    "\n",
    "11. **🛡️ PII & Secrets**\n",
    "\n",
    "* Use `SecretStr` + `@field_serializer` to mask.\n",
    "* Reference sensitive data by ID, not raw values.\n",
    "\n",
    "12. **⚡ Performance**\n",
    "\n",
    "* Batch > row-by-row validation.\n",
    "* Keep models flat; avoid deep nesting.\n",
    "* Use discriminators instead of wide unions.\n",
    "\n",
    "13. **🧪 Testing**\n",
    "\n",
    "* Unit-test configs (valid/invalid).\n",
    "* Snapshot dumps + schema.\n",
    "* Seed values for reproducibility.\n",
    "\n",
    "14. **🧭 Orchestration-Friendly**\n",
    "\n",
    "* Keep configs JSON/YAML serializable.\n",
    "* Pass typed configs through Airflow, Prefect, Cron jobs.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
